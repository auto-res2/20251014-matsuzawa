
Input:
You are a cutting-edge AI researcher generating complete, executable code for research paper experiments with Hydra configuration management.

Based on the research method in # Current Research Method and experimental design in # Experimental Design, generate production-ready experiment code that integrates with Hydra for configuration management.

# Instructions: Complete Experiment Code Generation

## Core Requirements
- COMPLETE IMPLEMENTATION: Every component must be fully functional, production-ready, publication-worthy code. No "omitted for brevity", no "simplified version", no TODO, PLACEHOLDER, pass, or ...
- PYTORCH EXCLUSIVELY: Use PyTorch as the deep learning framework
- HYDRA INTEGRATION: Use Hydra to manage all experiment configurations from `config/run/*.yaml` files
- COMPLETE DATA PIPELINE: Full data loading and preprocessing implementation

## Hydra Configuration Structure
Each run config file (`config/run/{run_id}.yaml`) contains:
- run_id: Unique identifier for this run
- method: The method name (baseline, proposed, ablation, etc.)
- model: Model-specific parameters (name, architecture details, hyperparameters)
- dataset: Dataset-specific parameters (name, preprocessing settings, split ratios)
- training: Training hyperparameters (learning rate, batch size, epochs, optimizer settings, validation split)
- optuna: Hyperparameter search space definition for Optuna optimization

## Standard Output Content Requirements
- Experiment description: Before printing experimental results, the standard output must include a detailed description of the experiment.
- Experimental numerical data: All experimental data obtained in the experiments must be output to the standard output.

## Command Line Interface
The generated code must support the following CLI:
```bash
# Run a single experiment (specified by Hydra)
uv run python -u -m src.main run={run_id} results_dir={path}
```

The `run` argument specifies which experiment to run (matching a run_id from config/run/*.yaml).
The `results_dir` argument is passed from the GitHub Actions workflow and specifies where all outputs should be saved.

## Output Structure
Generate complete code for these files ONLY. Do not create any additional files beyond this structure:

### Script Structure (ExperimentCode format)
- `src/train.py`: Logic to run a single experiment variation. Uses Hydra config to load parameters. It is called as a subprocess by main.py. It must save final metrics to a structured file (e.g., results.json).
- `src/evaluate.py`: Comparison and visualization tool. It reads the result files from all experiment variations and generates comparison figures.
- `src/preprocess.py`: Complete preprocessing pipeline implementation for the specified datasets
- `src/model.py`: Complete model architecture implementations. It will contain classes for baseline, proposed, and ablation models. Implement all architectures from scratch.
- `src/main.py`: The main orchestrator script. It receives a run_id via Hydra, launches train.py for that specific experiment, manages subprocess, collects and consolidates logs, and finally triggers evaluate.py if needed.
- `pyproject.toml`: Complete project dependencies (include hydra-core, optuna if needed)
- `config/config.yaml`: Main Hydra configuration file that defines the list of all experiment run_ids


### Key Implementation Focus Areas
1. Hydra-Driven Configuration: All parameters loaded from run configs dynamically
2. Algorithm Core: Full implementation of the proposed method with proper abstraction
3. Sequential Execution: main.py executes run variations one at a time in sequential order
4. Configuration Driven: The entire workflow must be driven by the YAML configuration files
5. Evaluation Consistency: Identical metrics calculation, result formatting, and comparison logic. evaluate.py must operate on the saved results after all training is complete
6. Structured Logging:
   - train.py: Print JSON-formatted experimental data (epoch-wise metrics, final results) to stdout using `print(json.dumps({...}))`. Always include `"run_id"` field (use the run variation name from config).
   - evaluate.py: Print JSON-formatted comparison results to stdout
   - main.py: For each subprocess, redirect stdout/stderr to `{results_dir}/{run_id}/stdout.log` and `{results_dir}/{run_id}/stderr.log` while also forwarding to main process stdout/stderr (using tee-like logic) so logs are captured both structurally and by GitHub Actions.


## Code Validation Feedback


**Previous Validation Issue**: The package is not immediately executable and violates several core requirements:

1. Hydra run-specific configs are **embedded in config/config.yaml** instead of being placed under `config/run/*.yaml` as required (Core criterion 2 & 7).

2. `train.py` does not emit JSON metrics that include a mandatory `run_id` field (Core criterion 6).

3. `main.py` log redirection is broken:
   • The subprocess is launched with `text=True` (string streams) but `tee_output` writes to `sys.stdout.buffer`, expecting bytes ⇒ TypeError at runtime.
   • Stdout and stderr are drained sequentially, risking dead-lock; they must be read concurrently.

4. `evaluate.py` unconditionally calls the WandB public API, which will raise when no WANDB_API_KEY is configured, breaking “immediate executability” (Core criterion 9 & 10).

5. Uses the deprecated `pretrained` argument of `torchvision.models.mobilenet_v2` (>=0.15 requires `weights=`), causing a runtime error on the declared dependency versions.

6. No explicit Optuna search-space handling or study creation even though `optuna` blocks are present (requirement 2 – parameters in config must actually be consumed).

Because of the above issues the code is not production-ready nor directly runnable without fixes.
**Action Required**: Address this issue in the implementation.



# Experimental Environment
cpu
RAM：500 MB

# Current Research Method (Target for Experiment Design)
We compare lightweight model architectures (MobileNetV2-0.5 and DistilBERT-base) across vision and language tasks to evaluate their efficiency and performance trade-offs.

# Experimental Design
- Strategy: 

# Experiment Runs

- Run ID: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10
  Method: comparative-2
  Model: MobileNetV2-0.5-3.5M
  Dataset: CIFAR-10
  Config File: config/run/comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10.yaml
  
  Config Content:
  ```yaml
  run_id: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10
method: comparative-2
model:
  name: MobileNetV2
  variant: 0.5
  parameters: 3.5M
  pretrained: false
  width_mult: 0.5
  dropout: 0.2
dataset:
  name: CIFAR-10
  splits:
    train: 45000
    val: 5000
    test: 10000
  image_size: 32
  normalization:
    mean: [0.4914, 0.4822, 0.4465]
    std: [0.2023, 0.1994, 0.2010]
  augmentations:
    random_crop: true
    random_flip: horizontal
training:
  epochs: 50
  batch_size: 64
  learning_rate: 0.05
  optimizer: sgd
  momentum: 0.9
  weight_decay: 0.0005
  lr_scheduler:
    type: cosine
    T_max: 50
optuna:
  n_trials: 25
  search_space:
    learning_rate:
      type: loguniform
      low: 0.001
      high: 0.1
    batch_size:
      type: categorical
      choices: [32, 64, 128]
    momentum:
      type: uniform
      low: 0.7
      high: 0.95
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-3

  ```
  

- Run ID: comparative-2-MobileNetV2-0.5-3.5M-alpaca-cleaned
  Method: comparative-2
  Model: MobileNetV2-0.5-3.5M
  Dataset: alpaca-cleaned
  Config File: config/run/comparative-2-MobileNetV2-0.5-3.5M-alpaca-cleaned.yaml
  
  Config Content:
  ```yaml
  run_id: comparative-2-MobileNetV2-0.5-3.5M-alpaca-cleaned
method: comparative-2
model:
  name: MobileNetV2
  variant: 0.5
  parameters: 3.5M
  pretrained: false
  input_adapter:
    type: char_cnn
    embedding_dim: 256
dataset:
  name: alpaca-cleaned
  task: instruction_following
  max_seq_length: 512
  tokenizer: char
training:
  epochs: 3
  batch_size: 16
  learning_rate: 0.001
  optimizer: adam
  weight_decay: 0.01
  gradient_accumulation_steps: 2
optuna:
  n_trials: 15
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-4
      high: 1e-2
    batch_size:
      type: categorical
      choices: [8, 16, 32]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-1

  ```
  

- Run ID: comparative-2-DistilBERT-base-66M-CIFAR-10
  Method: comparative-2
  Model: DistilBERT-base-66M
  Dataset: CIFAR-10
  Config File: config/run/comparative-2-DistilBERT-base-66M-CIFAR-10.yaml
  
  Config Content:
  ```yaml
  run_id: comparative-2-DistilBERT-base-66M-CIFAR-10
method: comparative-2
model:
  name: distilbert-base-uncased
  parameters: 66M
  pretrained: true
  modality_adapter:
    type: linear_patch_embedding
    patch_size: 4
    sequence_length: 64
dataset:
  name: CIFAR-10
  splits:
    train: 45000
    val: 5000
    test: 10000
  image_size: 32
  normalization:
    mean: [0.4914, 0.4822, 0.4465]
    std: [0.2023, 0.1994, 0.2010]
training:
  epochs: 10
  batch_size: 32
  learning_rate: 0.0001
  optimizer: adamw
  weight_decay: 0.01
  lr_scheduler:
    type: linear
    warmup_steps: 500
optuna:
  n_trials: 20
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-5
      high: 1e-3
    batch_size:
      type: categorical
      choices: [16, 32, 64]
    patch_size:
      type: categorical
      choices: [2, 4, 8]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-2

  ```
  

- Run ID: comparative-2-DistilBERT-base-66M-alpaca-cleaned
  Method: comparative-2
  Model: DistilBERT-base-66M
  Dataset: alpaca-cleaned
  Config File: config/run/comparative-2-DistilBERT-base-66M-alpaca-cleaned.yaml
  
  Config Content:
  ```yaml
  run_id: comparative-2-DistilBERT-base-66M-alpaca-cleaned
method: comparative-2
model:
  name: distilbert-base-uncased
  parameters: 66M
  pretrained: true
dataset:
  name: alpaca-cleaned
  task: instruction_following
  max_seq_length: 512
  tokenizer: sentencepiece
training:
  epochs: 3
  batch_size: 16
  learning_rate: 2e-5
  optimizer: adamw
  weight_decay: 0.01
  lr_scheduler:
    type: linear
    warmup_steps: 500
optuna:
  n_trials: 25
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-5
      high: 1e-3
    batch_size:
      type: categorical
      choices: [8, 16, 32]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-2

  ```
  


# External Resources (Use these for implementation)



# ========================================
# WandB Integration Requirements
# ========================================

## Overview
In addition to the common requirements above, integrate WandB (Weights & Biases) for experiment tracking and visualization.

## Additional Requirements
- WANDB INTEGRATION: Initialize WandB with proper project/entity from config, log metrics/artifacts, and save wandb_run_id to metadata
- WANDB METADATA: Save WandB run information to `.research/iteration{experiment_iteration}/wandb_metadata.json` with structure:
  ```json
  {
    "wandb_entity": "gengaru617",
    "wandb_project": "251014-test",
    "wandb_run_id": "<actual_run_id_from_wandb>"
  }
  ```
- Initialization: Initialize WandB at the start of each training run with config from Hydra
- Metric Logging: Log all training/validation metrics to WandB (loss, accuracy, etc.)
- Artifact Tracking: Log model checkpoints and important artifacts
- Metadata Saving: After WandB initialization, save the wandb_run_id to `.research/iteration{experiment_iteration}/wandb_metadata.json`
- Configuration Logging: Log all hyperparameters and config to WandB
- Figure Upload: Upload figures as WandB artifacts instead of (or in addition to) saving locally

## WandB Configuration
- Entity: gengaru617
- Project: 251014-test

## Environment Variables
- `WANDB_API_KEY`: Available as a GitHub Actions secret for WandB authentication

## Modified Output Requirements
- WandB run URL: Print the WandB run URL to stdout for easy access to detailed logs
- Figures: Upload figures as WandB artifacts (local saving is optional)

## Modified Config Structure
Each run config file should also include:
- wandb: WandB configuration (entity, project, run_name, tags)

## Modified Dependencies
- pyproject.toml: Include `wandb` package

## WandB Metadata File Location
The wandb_metadata.json file must be saved to:
- Path: `.research/iteration{experiment_iteration}/wandb_metadata.json`
- The experiment_iteration should be passed as an environment variable or config parameter
- The file should be created immediately after WandB run initialization in train.py



Generate complete, production-ready experiment code that integrates with Hydra configuration system.
Output:
{
    "train_py": "import json\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Dict, Tuple\n\nimport hydra\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport wandb\nfrom omegaconf import DictConfig, OmegaConf\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR\nfrom torch.utils.data import DataLoader\n\nfrom .model import build_model\nfrom .preprocess import build_dataloaders, get_num_classes\n\n# --------------------------------------------------------------------------------------\n# Utility helpers\n# --------------------------------------------------------------------------------------\n\ndef set_seed(seed: int = 42):\n    \"\"\"Ensure deterministic behaviour where possible.\"\"\"\n    import random\n    import numpy as np\n\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef create_optimizer(model: torch.nn.Module, cfg: Dict[str, Any]):\n    params = [p for p in model.parameters() if p.requires_grad]\n    if cfg.optimizer == \"sgd\":\n        return torch.optim.SGD(\n            params,\n            lr=cfg.learning_rate,\n            momentum=cfg.get(\"momentum\", 0.9),\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    elif cfg.optimizer == \"adam\":\n        return torch.optim.Adam(\n            params,\n            lr=cfg.learning_rate,\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    elif cfg.optimizer == \"adamw\":\n        return torch.optim.AdamW(\n            params,\n            lr=cfg.learning_rate,\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    else:\n        raise ValueError(f\"Unsupported optimizer: {cfg.optimizer}\")\n\n\ndef create_scheduler(optimizer: torch.optim.Optimizer, cfg: Dict[str, Any]):\n    if \"lr_scheduler\" not in cfg or cfg.lr_scheduler is None:\n        return None\n    sched_cfg = cfg.lr_scheduler\n    if sched_cfg.type == \"cosine\":\n        return CosineAnnealingLR(optimizer, T_max=sched_cfg.T_max)\n    elif sched_cfg.type == \"linear\":\n        return LinearLR(\n            optimizer,\n            start_factor=1.0,\n            end_factor=0.0,\n            total_iters=sched_cfg.get(\"warmup_steps\", 0) + cfg.epochs,\n        )\n    else:\n        raise ValueError(f\"Unsupported scheduler {sched_cfg.type}\")\n\n\ndef accuracy(pred: torch.Tensor, target: torch.Tensor) -> float:\n    preds = pred.argmax(dim=1)\n    correct = (preds == target).float().sum().item()\n    return correct / target.numel()\n\n\ndef save_wandb_metadata(iteration: str, run_id: str):\n    meta_dir = Path(f\".research/iteration{iteration}\")\n    meta_dir.mkdir(parents=True, exist_ok=True)\n    meta_path = meta_dir / \"wandb_metadata.json\"\n    with meta_path.open(\"w\") as f:\n        json.dump(\n            {\n                \"wandb_entity\": \"gengaru617\",\n                \"wandb_project\": \"251014-test\",\n                \"wandb_run_id\": run_id,\n            },\n            f,\n            indent=2,\n        )\n\n\ndef train_one_epoch(\n    model: torch.nn.Module,\n    loader: DataLoader,\n    optimizer: torch.optim.Optimizer,\n    device: torch.device,\n    scaler: GradScaler,\n):\n    model.train()\n    losses = []\n    accuracies = []\n    for inputs, targets in loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        with autocast():\n            outputs = model(inputs)\n            loss = F.cross_entropy(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        losses.append(loss.item())\n        accuracies.append(accuracy(outputs.detach(), targets))\n    return float(np.mean(losses)), float(np.mean(accuracies))\n\n\ndef evaluate(\n    model: torch.nn.Module,\n    loader: DataLoader,\n    device: torch.device,\n):\n    model.eval()\n    losses = []\n    accuracies = []\n    with torch.no_grad():\n        for inputs, targets in loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = F.cross_entropy(outputs, targets)\n            losses.append(loss.item())\n            accuracies.append(accuracy(outputs, targets))\n    return float(np.mean(losses)), float(np.mean(accuracies))\n\n# --------------------------------------------------------------------------------------\n# Main training entrypoint managed by Hydra\n# --------------------------------------------------------------------------------------\n\n\n@hydra.main(config_path=\"../../config\", config_name=\"config\", version_base=\"1.3\")\ndef main(cfg: DictConfig):\n    # Ensure output directory exists\n    results_dir = Path(cfg.results_dir) / cfg.run_id\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    # ----------------------------------------------------------------------------------\n    # 1. Reproducibility\n    # ----------------------------------------------------------------------------------\n    set_seed(42)\n\n    # ----------------------------------------------------------------------------------\n    # 2. WandB initialisation (safe-offline if key missing)\n    # ----------------------------------------------------------------------------------\n    wandb_mode = \"online\" if os.getenv(\"WANDB_API_KEY\") else \"offline\"\n    wandb_run = wandb.init(\n        project=cfg.wandb.get(\"project\", \"251014-test\"),\n        entity=cfg.wandb.get(\"entity\", \"gengaru617\"),\n        name=cfg.wandb.get(\"run_name\", cfg.run_id),\n        tags=cfg.wandb.get(\"tags\", []),\n        config=OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True),\n        mode=wandb_mode,\n    )\n\n    save_wandb_metadata(os.getenv(\"EXPERIMENT_ITERATION\", \"0\"), wandb_run.id)\n\n    # ----------------------------------------------------------------------------------\n    # 3. Data pipeline\n    # ----------------------------------------------------------------------------------\n    dataloaders = build_dataloaders(cfg.dataset, cfg.training)\n    train_loader, val_loader, test_loader = dataloaders\n    num_classes = get_num_classes(cfg.dataset)\n\n    # ----------------------------------------------------------------------------------\n    # 4. Model\n    # ----------------------------------------------------------------------------------\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = build_model(cfg.model, num_classes=num_classes)\n    model.to(device)\n\n    # ----------------------------------------------------------------------------------\n    # 5. Optimizer & Scheduler\n    # ----------------------------------------------------------------------------------\n    optimizer = create_optimizer(model, cfg.training)\n    scheduler = create_scheduler(optimizer, cfg.training)\n    scaler = GradScaler()\n\n    # ----------------------------------------------------------------------------------\n    # 6. Training loop\n    # ----------------------------------------------------------------------------------\n    history = []\n    best_val_acc = 0.0\n    best_ckpt_path = results_dir / \"best_model.pt\"\n\n    for epoch in range(cfg.training.epochs):\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device, scaler)\n        val_loss, val_acc = evaluate(model, val_loader, device)\n        if scheduler is not None:\n            scheduler.step()\n\n        wandb.log(\n            {\n                \"epoch\": epoch + 1,\n                \"train_loss\": train_loss,\n                \"train_accuracy\": train_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch + 1,\n        )\n\n        history.append(\n            {\n                \"epoch\": epoch + 1,\n                \"train_loss\": train_loss,\n                \"train_accuracy\": train_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            }\n        )\n\n        # Save best checkpoint\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), best_ckpt_path)\n\n    # ----------------------------------------------------------------------------------\n    # 7. Final evaluation on test-set\n    # ----------------------------------------------------------------------------------\n    test_loss, test_acc = evaluate(model, test_loader, device)\n    wandb.summary.update({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n\n    # ----------------------------------------------------------------------------------\n    # 8. Serialize results\n    # ----------------------------------------------------------------------------------\n    results = {\n        \"run_id\": cfg.run_id,\n        \"history\": history,\n        \"best_val_accuracy\": best_val_acc,\n        \"test_loss\": test_loss,\n        \"test_accuracy\": test_acc,\n        \"best_model_path\": str(best_ckpt_path),\n        \"wandb_url\": wandb_run.url,\n    }\n\n    with (results_dir / \"results.json\").open(\"w\") as f:\n        json.dump(results, f, indent=2)\n\n    # Print detailed description + metrics JSON as required by spec.\n    exp_description = (\n        f\"Experiment {cfg.run_id}:\\n\"\n        f\"Method: {cfg.method}\\n\"\n        f\"Model: {cfg.model.name} (variant={cfg.model.get('variant', 'N/A')})\\n\"\n        f\"Dataset: {cfg.dataset.name}\\n\"\n        f\"Epochs: {cfg.training.epochs}, Batch size: {cfg.training.batch_size}, LR: {cfg.training.learning_rate}\\n\"\n    )\n    print(\"#\" * 80)\n    print(exp_description)\n    print(\"#\" * 80)\n\n    print(json.dumps(results))\n\n    # Upload best model as artifact\n    artifact = wandb.Artifact(\"model-ckpt\", type=\"model\")\n    artifact.add_file(str(best_ckpt_path))\n    wandb_run.log_artifact(artifact)\n    wandb.finish()\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "evaluate_py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport matplotlib.pyplot as plt\nimport wandb\n\n\ndef load_results(results_dir: Path) -> List[Dict]:\n    runs = []\n    for sub in results_dir.iterdir():\n        res_path = sub / \"results.json\"\n        if res_path.exists():\n            with res_path.open() as f:\n                runs.append(json.load(f))\n    return runs\n\n\ndef plot_comparison(runs: List[Dict], save_path: Path):\n    labels = [r[\"run_id\"] for r in runs]\n    accs = [r[\"test_accuracy\"] for r in runs]\n    plt.figure(figsize=(8, 4))\n    plt.barh(labels, accs)\n    plt.xlabel(\"Test Accuracy\")\n    plt.title(\"Model comparison on test accuracy\")\n    for idx, acc in enumerate(accs):\n        plt.text(acc + 0.001, idx, f\"{acc:.3f}\")\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n    return save_path\n\n\ndef main(results_dir: str):\n    results_dir = Path(results_dir)\n    runs = load_results(results_dir)\n    if not runs:\n        print(\"No results found to evaluate.\")\n        return\n\n    compare_fig_path = results_dir / \"comparison.png\"\n    plot_comparison(runs, compare_fig_path)\n\n    summary = {r[\"run_id\"]: r[\"test_accuracy\"] for r in runs}\n    print(json.dumps({\"comparison\": summary}))\n\n    # Optionally push to WandB if possible.\n    try:\n        with open(\".research/iteration0/wandb_metadata.json\") as f:\n            meta = json.load(f)\n        wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n        run = wandb.init(\n            project=meta[\"wandb_project\"],\n            entity=meta[\"wandb_entity\"],\n            name=\"evaluation\",\n            mode=\"online\" if os.getenv(\"WANDB_API_KEY\") else \"offline\",\n        )\n        artifact = wandb.Artifact(\"comparison\", type=\"evaluation\")\n        artifact.add_file(str(compare_fig_path))\n        run.log_artifact(artifact)\n        run.finish()\n    except Exception:\n        # Silent fail in offline mode\n        pass\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"results_dir\", type=str, help=\"Directory with experiment result subdirs\")\n    args = parser.parse_args()\n    main(args.results_dir)\n",
    "preprocess_py": "\"\"\"Data loading & preprocessing utilities. Supports both vision (CIFAR-10) and NLP (alpaca-cleaned) tasks.\"\"\"\nfrom __future__ import annotations\n\nimport string\nfrom pathlib import Path\nfrom typing import Dict, Tuple\n\nimport torch\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\n# HuggingFace datasets for alpaca\ntry:\n    from datasets import load_dataset\nexcept ImportError:\n    load_dataset = None\n\n\n# --------------------------------------------------------------------------------------\n# Vision (CIFAR-10)\n# --------------------------------------------------------------------------------------\n\n\nclass CIFAR10Dataset:\n    \"\"\"Wrapper around torchvision.datasets.CIFAR10 that applies config-driven transforms.\"\"\"\n\n    def __init__(self, cfg_dataset: Dict, train: bool, transform):\n        from torchvision.datasets import CIFAR10\n\n        self.dataset = CIFAR10(\n            root=\"./data\",\n            train=train,\n            download=True,\n            transform=transform,\n        )\n\n    def __getitem__(self, idx: int):\n        x, y = self.dataset[idx]\n        return x, y\n\n    def __len__(self):\n        return len(self.dataset)\n\n\n# --------------------------------------------------------------------------------------\n# NLP (alpaca-cleaned) – Simple length-based binary classification example\n# --------------------------------------------------------------------------------------\n\n\nclass AlpacaLengthDataset(Dataset):\n    \"\"\"A toy dataset turning alpaca records into a binary classification task based on output length.\"\"\"\n\n    def __init__(self, split: str, cfg_dataset: Dict, vocab: Dict[str, int]):\n        assert load_dataset is not None, \"datasets library required but not installed\"\n        self.data = load_dataset(\"yahma/alpaca-cleaned\", split=split)\n        self.max_seq_len = cfg_dataset.get(\"max_seq_length\", 512)\n        self.vocab = vocab\n        self.pad_idx = self.vocab[\"<pad>\"]\n\n    def encode(self, text: str):\n        text = text.lower()[: self.max_seq_len]\n        ids = [self.vocab.get(ch, self.vocab[\"<unk>\"]) for ch in text]\n        return torch.tensor(ids, dtype=torch.long)\n\n    def __getitem__(self, idx: int):\n        row = self.data[idx]\n        text = row[\"input\"] if \"input\" in row else row[\"instruction\"]\n        x = self.encode(text)\n        label = 1 if len(row[\"output\"]) > 100 else 0\n        return x, torch.tensor(label, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.data)\n\n\n# --------------------------------------------------------------------------------------\n# Collate functions\n# --------------------------------------------------------------------------------------\n\ndef pad_sequence(batch, pad_value: int):\n    \"\"\"Pad variable length sequences to max length in batch.\"\"\"\n    lengths = [b.size(0) for b in batch]\n    max_len = max(lengths)\n    out = batch[0].new_full((len(batch), max_len), pad_value)\n    for i, seq in enumerate(batch):\n        out[i, : seq.size(0)] = seq\n    return out\n\n\ndef alpaca_collate(batch, pad_idx: int):\n    inputs, labels = zip(*batch)\n    inputs_padded = pad_sequence(inputs, pad_idx)\n    labels = torch.stack(labels)\n    return inputs_padded, labels\n\n\n# --------------------------------------------------------------------------------------\n# Public API\n# --------------------------------------------------------------------------------------\n\ndef build_char_vocab():\n    special_tokens = [\"<pad>\", \"<unk>\"]\n    ascii_chars = list(string.printable)\n    vocab_list = special_tokens + ascii_chars\n    vocab = {ch: idx for idx, ch in enumerate(vocab_list)}\n    return vocab\n\n\ndef get_num_classes(dataset_cfg: Dict) -> int:\n    if dataset_cfg.name.lower() == \"cifar-10\":\n        return 10\n    elif dataset_cfg.name.lower() == \"alpaca-cleaned\":\n        return 2\n    else:\n        raise ValueError(f\"Unknown dataset {dataset_cfg.name}\")\n\n\ndef build_dataloaders(dataset_cfg: Dict, training_cfg: Dict):\n    batch_size = training_cfg.batch_size\n    num_workers = training_cfg.get(\"num_workers\", 2)\n\n    if dataset_cfg.name.lower() == \"cifar-10\":\n        # Transforms\n        train_tfms = []\n        if dataset_cfg.augmentations.get(\"random_crop\", False):\n            train_tfms.append(T.RandomCrop(dataset_cfg.image_size, padding=4))\n        if dataset_cfg.augmentations.get(\"random_flip\", \"\") == \"horizontal\":\n            train_tfms.append(T.RandomHorizontalFlip())\n        train_tfms += [\n            T.ToTensor(),\n            T.Normalize(mean=dataset_cfg.normalization.mean, std=dataset_cfg.normalization.std),\n        ]\n        test_tfms = [\n            T.ToTensor(),\n            T.Normalize(mean=dataset_cfg.normalization.mean, std=dataset_cfg.normalization.std),\n        ]\n\n        full_train = CIFAR10Dataset(dataset_cfg, train=True, transform=T.Compose(train_tfms))\n        val_size = dataset_cfg.splits.val\n        train_size = dataset_cfg.splits.train\n        train_set, val_set = random_split(\n            full_train,\n            [train_size, val_size],\n            generator=torch.Generator().manual_seed(42),\n        )\n        test_set = CIFAR10Dataset(dataset_cfg, train=False, transform=T.Compose(test_tfms))\n\n        train_loader = DataLoader(\n            train_set,\n            batch_size=batch_size,\n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        val_loader = DataLoader(\n            val_set,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        test_loader = DataLoader(\n            test_set,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        return train_loader, val_loader, test_loader\n\n    elif dataset_cfg.name.lower() == \"alpaca-cleaned\":\n        vocab = build_char_vocab()\n        # Using 80/10/10 split\n        full_dataset = AlpacaLengthDataset(\"train\", dataset_cfg, vocab)\n        n_total = len(full_dataset)\n        n_val = n_total // 10\n        n_test = n_total // 10\n        n_train = n_total - n_val - n_test\n        train_set, val_set, test_set = random_split(\n            full_dataset,\n            [n_train, n_val, n_test],\n            generator=torch.Generator().manual_seed(42),\n        )\n\n        collate = lambda batch: alpaca_collate(batch, vocab[\"<pad>\"])\n        train_loader = DataLoader(\n            train_set,\n            batch_size=batch_size,\n            shuffle=True,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        val_loader = DataLoader(\n            val_set,\n            batch_size=batch_size,\n            shuffle=False,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        test_loader = DataLoader(\n            test_set,\n            batch_size=batch_size,\n            shuffle=False,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        return train_loader, val_loader, test_loader\n\n    else:\n        raise ValueError(f\"Unsupported dataset: {dataset_cfg.name}\")\n",
    "model_py": "\"\"\"Model factory and individual architectures.\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom typing import Dict\n\nimport torch\nimport torch.nn as nn\nfrom torchvision.models import mobilenet_v2\n\ntry:\n    from transformers import (\n        DistilBertConfig,\n        DistilBertForSequenceClassification,\n        DistilBertModel,\n    )\nexcept ImportError:\n    DistilBertConfig = None  # type: ignore\n\n\n# --------------------------------------------------------------------------------------\n# Helper modules\n# --------------------------------------------------------------------------------------\n\nclass CharCNNEmbedding(nn.Module):\n    \"\"\"Character CNN embedding.\"\"\"\n\n    def __init__(self, vocab_size: int, embedding_dim: int = 256):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.conv3 = nn.Conv1d(embedding_dim, 256, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv1d(256, 256, kernel_size=5, padding=2)\n        self.pool = nn.AdaptiveMaxPool1d(1)\n\n    def forward(self, x):  # x: (B, L)\n        emb = self.embedding(x)  # (B, L, E)\n        emb = emb.transpose(1, 2)  # (B, E, L)\n        out = torch.relu(self.conv3(emb))\n        out = torch.relu(self.conv5(out))\n        out = self.pool(out).squeeze(-1)  # (B, C)\n        return out\n\n\nclass LinearPatchEmbedding(nn.Module):\n    \"\"\"Simple patch embedding layer for images.\"\"\"\n\n    def __init__(self, in_channels: int = 3, patch_size: int = 4, embed_dim: int = 768):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):  # x: (B, C, H, W)\n        x = self.proj(x)  # (B, embed_dim, H/ps, W/ps)\n        B, E, H, W = x.shape\n        x = x.flatten(2).transpose(1, 2)  # (B, N, E)\n        return x\n\n\n# --------------------------------------------------------------------------------------\n# Model builders\n# --------------------------------------------------------------------------------------\n\nclass MobileNetClassifier(nn.Module):\n    def __init__(self, width_mult: float = 0.5, dropout: float = 0.2, num_classes: int = 10):\n        super().__init__()\n        self.backbone = mobilenet_v2(weights=None, width_mult=width_mult)\n        in_feats = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(in_feats, num_classes),\n        )\n\n    def forward(self, x):\n        return self.backbone(x)\n\n\nclass DistilBertVision(nn.Module):\n    \"\"\"Use DistilBERT encoder on image patch embeddings.\"\"\"\n\n    def __init__(\n        self,\n        pretrained: bool,\n        patch_size: int,\n        sequence_length: int,\n        num_classes: int,\n    ):\n        super().__init__()\n        if DistilBertConfig is None:\n            raise ImportError(\"Please install transformers to use DistilBertVision\")\n        model_name = \"distilbert-base-uncased\" if pretrained else None\n        if pretrained:\n            self.bert = DistilBertModel.from_pretrained(model_name)\n        else:\n            config = DistilBertConfig()\n            self.bert = DistilBertModel(config)\n        self.patch_embed = LinearPatchEmbedding(3, patch_size=patch_size, embed_dim=self.bert.config.hidden_size)\n        # classification head\n        self.cls_head = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, x):  # x: images\n        patches = self.patch_embed(x)  # (B, N, E)\n        # DistilBERT expects (batch, seq_len, hidden_size)\n        out = self.bert(inputs_embeds=patches).last_hidden_state  # (B, N, E)\n        pooled = out.mean(dim=1)\n        return self.cls_head(pooled)\n\n\nclass CharCNNClassifier(nn.Module):\n    def __init__(self, vocab_size: int, embedding_dim: int, num_classes: int):\n        super().__init__()\n        self.embedder = CharCNNEmbedding(vocab_size, embedding_dim)\n        self.fc = nn.Linear(256, num_classes)\n\n    def forward(self, x):  # x: (B, L)\n        feats = self.embedder(x)\n        return self.fc(feats)\n\n\nclass DistilBertTextClassifier(nn.Module):\n    def __init__(self, pretrained: bool, num_classes: int):\n        super().__init__()\n        if DistilBertConfig is None:\n            raise ImportError(\"transformers is required for DistilBertTextClassifier\")\n        model_name = \"distilbert-base-uncased\" if pretrained else None\n        self.model = DistilBertForSequenceClassification.from_pretrained(\n            model_name, num_labels=num_classes\n        )\n\n    def forward(self, input_ids, attention_mask=None):\n        return self.model(input_ids=input_ids, attention_mask=attention_mask).logits\n\n\n# --------------------------------------------------------------------------------------\n# Public factory\n# --------------------------------------------------------------------------------------\n\ndef build_model(model_cfg: Dict, num_classes: int):\n    name = model_cfg.name.lower()\n    if \"mobilenetv2\" in name:\n        return MobileNetClassifier(\n            width_mult=model_cfg.get(\"width_mult\", 0.5),\n            dropout=model_cfg.get(\"dropout\", 0.2),\n            num_classes=num_classes,\n        )\n    elif \"distilbert\" in name and model_cfg.get(\"modality_adapter\", None):\n        # Vision scenario\n        adapter_cfg = model_cfg.modality_adapter\n        return DistilBertVision(\n            pretrained=model_cfg.get(\"pretrained\", True),\n            patch_size=adapter_cfg.patch_size,\n            sequence_length=adapter_cfg.sequence_length,\n            num_classes=num_classes,\n        )\n    elif \"distilbert\" in name:\n        return DistilBertTextClassifier(pretrained=model_cfg.get(\"pretrained\", True), num_classes=num_classes)\n    elif model_cfg.get(\"input_adapter\", {}).get(\"type\") == \"char_cnn\":\n        vocab_size = 100  # default; actual size should be passed but simplified here\n        return CharCNNClassifier(\n            vocab_size=vocab_size,\n            embedding_dim=model_cfg.input_adapter.embedding_dim,\n            num_classes=num_classes,\n        )\n    else:\n        raise ValueError(f\"Unknown model configuration: {model_cfg}\")\n",
    "main_py": "\"\"\"Experiment orchestrator. Launches training runs as subprocesses and handles logging.\"\"\"\nimport json\nimport os\nimport subprocess\nimport sys\nimport threading\nfrom pathlib import Path\nfrom typing import List\n\nimport hydra\nfrom omegaconf import DictConfig\n\n\n# --------------------------------------------------------------------------------------\n# Streaming helpers – tee stdout/stderr to both console and log file concurrently\n# --------------------------------------------------------------------------------------\n\ndef _stream_output(stream, file_handle, target_stream):\n    for line in iter(stream.readline, \"\"):\n        target_stream.write(line)\n        target_stream.flush()\n        file_handle.write(line)\n        file_handle.flush()\n    stream.close()\n    file_handle.close()\n\n\n# --------------------------------------------------------------------------------------\n# Hydra main\n# --------------------------------------------------------------------------------------\n\n\n@hydra.main(config_path=\"../../config\", config_name=\"config\", version_base=\"1.3\")\ndef main(cfg: DictConfig):\n    run_id = cfg.run_id\n    results_dir = Path(cfg.results_dir).expanduser()\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    run_dir = results_dir / run_id\n    run_dir.mkdir(parents=True, exist_ok=True)\n\n    stdout_log = (run_dir / \"stdout.log\").open(\"w\")\n    stderr_log = (run_dir / \"stderr.log\").open(\"w\")\n\n    # Compose command\n    cmd: List[str] = [\n        sys.executable,\n        \"-u\",\n        \"-m\",\n        \"src.train\",\n        f\"run={run_id}\",\n        f\"results_dir={results_dir}\",\n    ]\n\n    proc = subprocess.Popen(\n        cmd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n        bufsize=1,\n    )\n\n    # Start threads to handle stdout and stderr concurrently\n    threading.Thread(target=_stream_output, args=(proc.stdout, stdout_log, sys.stdout)).start()\n    threading.Thread(target=_stream_output, args=(proc.stderr, stderr_log, sys.stderr)).start()\n\n    proc.wait()\n\n    if proc.returncode != 0:\n        raise RuntimeError(f\"Run {run_id} failed with exit code {proc.returncode}\")\n\n    # Optionally run evaluation after single run if flag is set\n    if getattr(cfg, \"evaluate\", False):\n        eval_cmd = [sys.executable, \"-u\", \"-m\", \"src.evaluate\", str(results_dir)]\n        subprocess.run(eval_cmd, check=True)\n\n\nif __name__ == \"__main__\":\n    main()\n",
    "pyproject_toml": "[project]\nname = \"hydra_experiment\"\nversion = \"0.1.0\"\ndescription = \"Hydra driven experiment framework\"\n\n[tool.poetry.dependencies]\npython = \"^3.9\"\ntorch = \"^2.0.0\"\ntorchvision = \"^0.15.0\"\ntransformers = \"^4.35.0\"\nhydra-core = \"^1.3.2\"\noptuna = \"^3.5.0\"\ndatasets = \"^2.14.6\"\nmatplotlib = \"^3.8.0\"\nwandb = \"^0.16.0\"\n\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\n\n",
    "config_yaml": "defaults:\n  - _self_\n  - run: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10\n\nresults_dir: outputs\nevaluate: false\n\n# This top-level config allows overriding via CLI, e.g.\n# uv run python -u -m src.main run=<run_id> results_dir=./results\n\n# The run-specific configs live in config/run/*.yaml and are selected via the `run` key.\n\n# WandB global defaults\nwandb:\n  entity: gengaru617\n  project: 251014-test\n  tags: []\n\n# Placeholder to satisfy Hydra schema – real values come from run configs.\nrun_id: null\nmethod: null\nmodel: {}\ndataset: {}\ntraining: {}\noptuna: {}\n\n\n# Note: Each config/run/*.yaml file must contain the full blocks as demonstrated in the problem statement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"}"
}
