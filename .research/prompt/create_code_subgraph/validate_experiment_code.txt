
Input:
You are an AI code reviewer validating production-ready experiment code for research papers.

Analyze the provided experiment code and determine if it meets all requirements for immediate execution in research experiments.

# Instructions

## Core Validation Criteria
Check if the generated experiment code meets ALL of the following requirements:

1. **Complete Implementation**:
   - Every component is fully functional, production-ready, publication-worthy code
   - No "omitted for brevity", no "simplified version", no TODO, PLACEHOLDER, pass, or ...
   - All functions and classes are completely implemented
   - No truncated code sections or incomplete implementations

2. **Hydra Integration**:
   - Uses Hydra to manage all experiment configurations from `config/run/*.yaml` files
   - All parameters are loaded from run configs dynamically
   - Proper configuration structure with run_id, method, model, dataset, training, and optuna sections
   - CLI interface matches: `uv run python -u -m src.main run={run_id} results_dir={path}`

3. **Complete Data Pipeline**:
   - Full data loading and preprocessing implementation
   - Dataset-specific preprocessing is properly implemented
   - No placeholder dataset loading code
   - Proper error handling for data operations

4. **Model Implementation**:
   - Complete model architectures for baseline, proposed, and ablation methods
   - All models implemented from scratch (no placeholders)
   - Model-specific configurations correctly applied
   - Proper PyTorch usage throughout

5. **File Structure Compliance**:
   - Contains EXACTLY these required files:
     * `src/train.py`
     * `src/evaluate.py`
     * `src/preprocess.py`
     * `src/model.py`
     * `src/main.py`
     * `pyproject.toml`
     * `config/config.yaml`
   - No missing files from the structure
   - All functionality contained within specified files

6. **Structured Logging**:
   - train.py prints JSON-formatted metrics with `run_id` field using `print(json.dumps({...}))`
   - evaluate.py prints JSON-formatted comparison results to stdout
   - main.py redirects subprocess stdout/stderr to `{results_dir}/{run_id}/stdout.log` and `stderr.log`
   - Logs are forwarded to main process stdout/stderr for GitHub Actions capture

7. **Configuration Files**:
   - config/config.yaml contains list of all experiment run_ids
   - NOTE: config/run/{run_id}.yaml files are provided separately in the "Experiment Runs" section below (not in ExperimentCode)
   - The generated code must properly reference these config files via Hydra
   - All run configurations match the experiment_runs provided
   - Optuna search spaces are properly defined if applicable

8. **Evaluation and Figures** (if WandB not used):
   - Figure generation with proper formatting (PDF output to `{results_dir}/images/`)
   - Figures include legends, annotations, and proper labels
   - Uses `plt.tight_layout()` before saving
   - Consistent result formatting and comparison logic

9. **WandB Integration** (if WandB is used):
   - Proper WandB initialization with entity/project from config
   - Metrics logged to WandB during training
   - WandB run URL printed to stdout
   - Metadata saved to `.research/iteration{experiment_iteration}/wandb_metadata.json`
   - Figures uploaded as WandB artifacts

10. **Immediate Executability**:
    - Code can be run immediately without modifications
    - All imports and dependencies properly specified in pyproject.toml
    - No missing external resources or undefined variables
    - Proper module structure for `uv run python -m src.main` execution

## Detection of Common Issues
Flag the following problems if found:

- **Incomplete Implementation**: TODO, PLACEHOLDER, pass, ..., or any placeholder patterns
- **Truncation**: Code sections that appear shortened or simplified inappropriately
- **Missing Functionality**: Expected features not implemented
- **Configuration Issues**: Missing or incomplete run configs
- **Import Errors**: Missing dependencies or incorrect import statements
- **Not Executable**: Code that cannot be run immediately
- **Inconsistent Structure**: Files not matching required structure
- **Logging Issues**: Missing or incorrect JSON logging format

## Output Format
Respond with a JSON object containing:
- `is_code_ready`: boolean - true if ALL criteria are met, false otherwise
- `code_issue`: string - specific issues found if any criteria are not met, focusing on what needs to be fixed

# Current Research Method
We compare lightweight model architectures (MobileNetV2-0.5 and DistilBERT-base) across vision and language tasks to evaluate their efficiency and performance trade-offs.

# Experimental Design
- Strategy: Comparative analysis of efficient model architectures across vision and language tasks
- Proposed Method: Evaluate MobileNetV2 and DistilBERT variants for efficient deployment
- Evaluation Metrics: ['accuracy', 'f1_score', 'inference_time', 'model_size']

# Experiment Runs

- Run ID: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10
  Method: comparative-2
  Model: MobileNetV2-0.5-3.5M
  Dataset: CIFAR-10
  
  Config Content:
  ```yaml
  run_id: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10
method: comparative-2
model:
  name: MobileNetV2
  variant: 0.5
  parameters: 3.5M
  pretrained: false
  width_mult: 0.5
  dropout: 0.2
dataset:
  name: CIFAR-10
  splits:
    train: 45000
    val: 5000
    test: 10000
  image_size: 32
  normalization:
    mean: [0.4914, 0.4822, 0.4465]
    std: [0.2023, 0.1994, 0.2010]
  augmentations:
    random_crop: true
    random_flip: horizontal
training:
  epochs: 50
  batch_size: 64
  learning_rate: 0.05
  optimizer: sgd
  momentum: 0.9
  weight_decay: 0.0005
  lr_scheduler:
    type: cosine
    T_max: 50
optuna:
  n_trials: 25
  search_space:
    learning_rate:
      type: loguniform
      low: 0.001
      high: 0.1
    batch_size:
      type: categorical
      choices: [32, 64, 128]
    momentum:
      type: uniform
      low: 0.7
      high: 0.95
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-3

  ```
  

- Run ID: comparative-2-MobileNetV2-0.5-3.5M-alpaca-cleaned
  Method: comparative-2
  Model: MobileNetV2-0.5-3.5M
  Dataset: alpaca-cleaned
  
  Config Content:
  ```yaml
  run_id: comparative-2-MobileNetV2-0.5-3.5M-alpaca-cleaned
method: comparative-2
model:
  name: MobileNetV2
  variant: 0.5
  parameters: 3.5M
  pretrained: false
  input_adapter:
    type: char_cnn
    embedding_dim: 256
dataset:
  name: alpaca-cleaned
  task: instruction_following
  max_seq_length: 512
  tokenizer: char
training:
  epochs: 3
  batch_size: 16
  learning_rate: 0.001
  optimizer: adam
  weight_decay: 0.01
  gradient_accumulation_steps: 2
optuna:
  n_trials: 15
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-4
      high: 1e-2
    batch_size:
      type: categorical
      choices: [8, 16, 32]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-1

  ```
  

- Run ID: comparative-2-DistilBERT-base-66M-CIFAR-10
  Method: comparative-2
  Model: DistilBERT-base-66M
  Dataset: CIFAR-10
  
  Config Content:
  ```yaml
  run_id: comparative-2-DistilBERT-base-66M-CIFAR-10
method: comparative-2
model:
  name: distilbert-base-uncased
  parameters: 66M
  pretrained: true
  modality_adapter:
    type: linear_patch_embedding
    patch_size: 4
    sequence_length: 64
dataset:
  name: CIFAR-10
  splits:
    train: 45000
    val: 5000
    test: 10000
  image_size: 32
  normalization:
    mean: [0.4914, 0.4822, 0.4465]
    std: [0.2023, 0.1994, 0.2010]
training:
  epochs: 10
  batch_size: 32
  learning_rate: 0.0001
  optimizer: adamw
  weight_decay: 0.01
  lr_scheduler:
    type: linear
    warmup_steps: 500
optuna:
  n_trials: 20
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-5
      high: 1e-3
    batch_size:
      type: categorical
      choices: [16, 32, 64]
    patch_size:
      type: categorical
      choices: [2, 4, 8]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-2

  ```
  

- Run ID: comparative-2-DistilBERT-base-66M-alpaca-cleaned
  Method: comparative-2
  Model: DistilBERT-base-66M
  Dataset: alpaca-cleaned
  
  Config Content:
  ```yaml
  run_id: comparative-2-DistilBERT-base-66M-alpaca-cleaned
method: comparative-2
model:
  name: distilbert-base-uncased
  parameters: 66M
  pretrained: true
dataset:
  name: alpaca-cleaned
  task: instruction_following
  max_seq_length: 512
  tokenizer: sentencepiece
training:
  epochs: 3
  batch_size: 16
  learning_rate: 2e-5
  optimizer: adamw
  weight_decay: 0.01
  lr_scheduler:
    type: linear
    warmup_steps: 500
optuna:
  n_trials: 25
  search_space:
    learning_rate:
      type: loguniform
      low: 1e-5
      high: 1e-3
    batch_size:
      type: categorical
      choices: [8, 16, 32]
    weight_decay:
      type: loguniform
      low: 1e-5
      high: 1e-2

  ```
  


# Generated Experiment Code (To be validated)
{"config_yaml": "defaults:\n  - _self_\n  - run: comparative-2-MobileNetV2-0.5-3.5M-CIFAR-10\n\nresults_dir: outputs\nevaluate: false\n\n# This top-level config allows overriding via CLI, e.g.\n# uv run python -u -m src.main run=\u003crun_id\u003e results_dir=./results\n\n# The run-specific configs live in config/run/*.yaml and are selected via the `run` key.\n\n# WandB global defaults\nwandb:\n  entity: gengaru617\n  project: 251014-test\n  tags: []\n\n# Placeholder to satisfy Hydra schema \u2013 real values come from run configs.\nrun_id: null\nmethod: null\nmodel: {}\ndataset: {}\ntraining: {}\noptuna: {}\n\n\n# Note: Each config/run/*.yaml file must contain the full blocks as demonstrated in the problem statement.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\"}", "evaluate_py": "import json\nimport os\nfrom pathlib import Path\nfrom typing import Dict, List\n\nimport matplotlib.pyplot as plt\nimport wandb\n\n\ndef load_results(results_dir: Path) -\u003e List[Dict]:\n    runs = []\n    for sub in results_dir.iterdir():\n        res_path = sub / \"results.json\"\n        if res_path.exists():\n            with res_path.open() as f:\n                runs.append(json.load(f))\n    return runs\n\n\ndef plot_comparison(runs: List[Dict], save_path: Path):\n    labels = [r[\"run_id\"] for r in runs]\n    accs = [r[\"test_accuracy\"] for r in runs]\n    plt.figure(figsize=(8, 4))\n    plt.barh(labels, accs)\n    plt.xlabel(\"Test Accuracy\")\n    plt.title(\"Model comparison on test accuracy\")\n    for idx, acc in enumerate(accs):\n        plt.text(acc + 0.001, idx, f\"{acc:.3f}\")\n    plt.tight_layout()\n    plt.savefig(save_path)\n    plt.close()\n    return save_path\n\n\ndef main(results_dir: str):\n    results_dir = Path(results_dir)\n    runs = load_results(results_dir)\n    if not runs:\n        print(\"No results found to evaluate.\")\n        return\n\n    compare_fig_path = results_dir / \"comparison.png\"\n    plot_comparison(runs, compare_fig_path)\n\n    summary = {r[\"run_id\"]: r[\"test_accuracy\"] for r in runs}\n    print(json.dumps({\"comparison\": summary}))\n\n    # Optionally push to WandB if possible.\n    try:\n        with open(\".research/iteration0/wandb_metadata.json\") as f:\n            meta = json.load(f)\n        wandb.login(key=os.getenv(\"WANDB_API_KEY\"))\n        run = wandb.init(\n            project=meta[\"wandb_project\"],\n            entity=meta[\"wandb_entity\"],\n            name=\"evaluation\",\n            mode=\"online\" if os.getenv(\"WANDB_API_KEY\") else \"offline\",\n        )\n        artifact = wandb.Artifact(\"comparison\", type=\"evaluation\")\n        artifact.add_file(str(compare_fig_path))\n        run.log_artifact(artifact)\n        run.finish()\n    except Exception:\n        # Silent fail in offline mode\n        pass\n\n\nif __name__ == \"__main__\":\n    import argparse\n\n    parser = argparse.ArgumentParser()\n    parser.add_argument(\"results_dir\", type=str, help=\"Directory with experiment result subdirs\")\n    args = parser.parse_args()\n    main(args.results_dir)\n", "main_py": "\"\"\"Experiment orchestrator. Launches training runs as subprocesses and handles logging.\"\"\"\nimport json\nimport os\nimport subprocess\nimport sys\nimport threading\nfrom pathlib import Path\nfrom typing import List\n\nimport hydra\nfrom omegaconf import DictConfig\n\n\n# --------------------------------------------------------------------------------------\n# Streaming helpers \u2013 tee stdout/stderr to both console and log file concurrently\n# --------------------------------------------------------------------------------------\n\ndef _stream_output(stream, file_handle, target_stream):\n    for line in iter(stream.readline, \"\"):\n        target_stream.write(line)\n        target_stream.flush()\n        file_handle.write(line)\n        file_handle.flush()\n    stream.close()\n    file_handle.close()\n\n\n# --------------------------------------------------------------------------------------\n# Hydra main\n# --------------------------------------------------------------------------------------\n\n\n@hydra.main(config_path=\"../../config\", config_name=\"config\", version_base=\"1.3\")\ndef main(cfg: DictConfig):\n    run_id = cfg.run_id\n    results_dir = Path(cfg.results_dir).expanduser()\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    run_dir = results_dir / run_id\n    run_dir.mkdir(parents=True, exist_ok=True)\n\n    stdout_log = (run_dir / \"stdout.log\").open(\"w\")\n    stderr_log = (run_dir / \"stderr.log\").open(\"w\")\n\n    # Compose command\n    cmd: List[str] = [\n        sys.executable,\n        \"-u\",\n        \"-m\",\n        \"src.train\",\n        f\"run={run_id}\",\n        f\"results_dir={results_dir}\",\n    ]\n\n    proc = subprocess.Popen(\n        cmd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.PIPE,\n        text=True,\n        bufsize=1,\n    )\n\n    # Start threads to handle stdout and stderr concurrently\n    threading.Thread(target=_stream_output, args=(proc.stdout, stdout_log, sys.stdout)).start()\n    threading.Thread(target=_stream_output, args=(proc.stderr, stderr_log, sys.stderr)).start()\n\n    proc.wait()\n\n    if proc.returncode != 0:\n        raise RuntimeError(f\"Run {run_id} failed with exit code {proc.returncode}\")\n\n    # Optionally run evaluation after single run if flag is set\n    if getattr(cfg, \"evaluate\", False):\n        eval_cmd = [sys.executable, \"-u\", \"-m\", \"src.evaluate\", str(results_dir)]\n        subprocess.run(eval_cmd, check=True)\n\n\nif __name__ == \"__main__\":\n    main()\n", "model_py": "\"\"\"Model factory and individual architectures.\"\"\"\nfrom __future__ import annotations\n\nimport math\nfrom typing import Dict\n\nimport torch\nimport torch.nn as nn\nfrom torchvision.models import mobilenet_v2\n\ntry:\n    from transformers import (\n        DistilBertConfig,\n        DistilBertForSequenceClassification,\n        DistilBertModel,\n    )\nexcept ImportError:\n    DistilBertConfig = None  # type: ignore\n\n\n# --------------------------------------------------------------------------------------\n# Helper modules\n# --------------------------------------------------------------------------------------\n\nclass CharCNNEmbedding(nn.Module):\n    \"\"\"Character CNN embedding.\"\"\"\n\n    def __init__(self, vocab_size: int, embedding_dim: int = 256):\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n        self.conv3 = nn.Conv1d(embedding_dim, 256, kernel_size=3, padding=1)\n        self.conv5 = nn.Conv1d(256, 256, kernel_size=5, padding=2)\n        self.pool = nn.AdaptiveMaxPool1d(1)\n\n    def forward(self, x):  # x: (B, L)\n        emb = self.embedding(x)  # (B, L, E)\n        emb = emb.transpose(1, 2)  # (B, E, L)\n        out = torch.relu(self.conv3(emb))\n        out = torch.relu(self.conv5(out))\n        out = self.pool(out).squeeze(-1)  # (B, C)\n        return out\n\n\nclass LinearPatchEmbedding(nn.Module):\n    \"\"\"Simple patch embedding layer for images.\"\"\"\n\n    def __init__(self, in_channels: int = 3, patch_size: int = 4, embed_dim: int = 768):\n        super().__init__()\n        self.patch_size = patch_size\n        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n\n    def forward(self, x):  # x: (B, C, H, W)\n        x = self.proj(x)  # (B, embed_dim, H/ps, W/ps)\n        B, E, H, W = x.shape\n        x = x.flatten(2).transpose(1, 2)  # (B, N, E)\n        return x\n\n\n# --------------------------------------------------------------------------------------\n# Model builders\n# --------------------------------------------------------------------------------------\n\nclass MobileNetClassifier(nn.Module):\n    def __init__(self, width_mult: float = 0.5, dropout: float = 0.2, num_classes: int = 10):\n        super().__init__()\n        self.backbone = mobilenet_v2(weights=None, width_mult=width_mult)\n        in_feats = self.backbone.classifier[1].in_features\n        self.backbone.classifier = nn.Sequential(\n            nn.Dropout(p=dropout),\n            nn.Linear(in_feats, num_classes),\n        )\n\n    def forward(self, x):\n        return self.backbone(x)\n\n\nclass DistilBertVision(nn.Module):\n    \"\"\"Use DistilBERT encoder on image patch embeddings.\"\"\"\n\n    def __init__(\n        self,\n        pretrained: bool,\n        patch_size: int,\n        sequence_length: int,\n        num_classes: int,\n    ):\n        super().__init__()\n        if DistilBertConfig is None:\n            raise ImportError(\"Please install transformers to use DistilBertVision\")\n        model_name = \"distilbert-base-uncased\" if pretrained else None\n        if pretrained:\n            self.bert = DistilBertModel.from_pretrained(model_name)\n        else:\n            config = DistilBertConfig()\n            self.bert = DistilBertModel(config)\n        self.patch_embed = LinearPatchEmbedding(3, patch_size=patch_size, embed_dim=self.bert.config.hidden_size)\n        # classification head\n        self.cls_head = nn.Linear(self.bert.config.hidden_size, num_classes)\n\n    def forward(self, x):  # x: images\n        patches = self.patch_embed(x)  # (B, N, E)\n        # DistilBERT expects (batch, seq_len, hidden_size)\n        out = self.bert(inputs_embeds=patches).last_hidden_state  # (B, N, E)\n        pooled = out.mean(dim=1)\n        return self.cls_head(pooled)\n\n\nclass CharCNNClassifier(nn.Module):\n    def __init__(self, vocab_size: int, embedding_dim: int, num_classes: int):\n        super().__init__()\n        self.embedder = CharCNNEmbedding(vocab_size, embedding_dim)\n        self.fc = nn.Linear(256, num_classes)\n\n    def forward(self, x):  # x: (B, L)\n        feats = self.embedder(x)\n        return self.fc(feats)\n\n\nclass DistilBertTextClassifier(nn.Module):\n    def __init__(self, pretrained: bool, num_classes: int):\n        super().__init__()\n        if DistilBertConfig is None:\n            raise ImportError(\"transformers is required for DistilBertTextClassifier\")\n        model_name = \"distilbert-base-uncased\" if pretrained else None\n        self.model = DistilBertForSequenceClassification.from_pretrained(\n            model_name, num_labels=num_classes\n        )\n\n    def forward(self, input_ids, attention_mask=None):\n        return self.model(input_ids=input_ids, attention_mask=attention_mask).logits\n\n\n# --------------------------------------------------------------------------------------\n# Public factory\n# --------------------------------------------------------------------------------------\n\ndef build_model(model_cfg: Dict, num_classes: int):\n    name = model_cfg.name.lower()\n    if \"mobilenetv2\" in name:\n        return MobileNetClassifier(\n            width_mult=model_cfg.get(\"width_mult\", 0.5),\n            dropout=model_cfg.get(\"dropout\", 0.2),\n            num_classes=num_classes,\n        )\n    elif \"distilbert\" in name and model_cfg.get(\"modality_adapter\", None):\n        # Vision scenario\n        adapter_cfg = model_cfg.modality_adapter\n        return DistilBertVision(\n            pretrained=model_cfg.get(\"pretrained\", True),\n            patch_size=adapter_cfg.patch_size,\n            sequence_length=adapter_cfg.sequence_length,\n            num_classes=num_classes,\n        )\n    elif \"distilbert\" in name:\n        return DistilBertTextClassifier(pretrained=model_cfg.get(\"pretrained\", True), num_classes=num_classes)\n    elif model_cfg.get(\"input_adapter\", {}).get(\"type\") == \"char_cnn\":\n        vocab_size = 100  # default; actual size should be passed but simplified here\n        return CharCNNClassifier(\n            vocab_size=vocab_size,\n            embedding_dim=model_cfg.input_adapter.embedding_dim,\n            num_classes=num_classes,\n        )\n    else:\n        raise ValueError(f\"Unknown model configuration: {model_cfg}\")\n", "preprocess_py": "\"\"\"Data loading \u0026 preprocessing utilities. Supports both vision (CIFAR-10) and NLP (alpaca-cleaned) tasks.\"\"\"\nfrom __future__ import annotations\n\nimport string\nfrom pathlib import Path\nfrom typing import Dict, Tuple\n\nimport torch\nimport torchvision.transforms as T\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\n# HuggingFace datasets for alpaca\ntry:\n    from datasets import load_dataset\nexcept ImportError:\n    load_dataset = None\n\n\n# --------------------------------------------------------------------------------------\n# Vision (CIFAR-10)\n# --------------------------------------------------------------------------------------\n\n\nclass CIFAR10Dataset:\n    \"\"\"Wrapper around torchvision.datasets.CIFAR10 that applies config-driven transforms.\"\"\"\n\n    def __init__(self, cfg_dataset: Dict, train: bool, transform):\n        from torchvision.datasets import CIFAR10\n\n        self.dataset = CIFAR10(\n            root=\"./data\",\n            train=train,\n            download=True,\n            transform=transform,\n        )\n\n    def __getitem__(self, idx: int):\n        x, y = self.dataset[idx]\n        return x, y\n\n    def __len__(self):\n        return len(self.dataset)\n\n\n# --------------------------------------------------------------------------------------\n# NLP (alpaca-cleaned) \u2013 Simple length-based binary classification example\n# --------------------------------------------------------------------------------------\n\n\nclass AlpacaLengthDataset(Dataset):\n    \"\"\"A toy dataset turning alpaca records into a binary classification task based on output length.\"\"\"\n\n    def __init__(self, split: str, cfg_dataset: Dict, vocab: Dict[str, int]):\n        assert load_dataset is not None, \"datasets library required but not installed\"\n        self.data = load_dataset(\"yahma/alpaca-cleaned\", split=split)\n        self.max_seq_len = cfg_dataset.get(\"max_seq_length\", 512)\n        self.vocab = vocab\n        self.pad_idx = self.vocab[\"\u003cpad\u003e\"]\n\n    def encode(self, text: str):\n        text = text.lower()[: self.max_seq_len]\n        ids = [self.vocab.get(ch, self.vocab[\"\u003cunk\u003e\"]) for ch in text]\n        return torch.tensor(ids, dtype=torch.long)\n\n    def __getitem__(self, idx: int):\n        row = self.data[idx]\n        text = row[\"input\"] if \"input\" in row else row[\"instruction\"]\n        x = self.encode(text)\n        label = 1 if len(row[\"output\"]) \u003e 100 else 0\n        return x, torch.tensor(label, dtype=torch.long)\n\n    def __len__(self):\n        return len(self.data)\n\n\n# --------------------------------------------------------------------------------------\n# Collate functions\n# --------------------------------------------------------------------------------------\n\ndef pad_sequence(batch, pad_value: int):\n    \"\"\"Pad variable length sequences to max length in batch.\"\"\"\n    lengths = [b.size(0) for b in batch]\n    max_len = max(lengths)\n    out = batch[0].new_full((len(batch), max_len), pad_value)\n    for i, seq in enumerate(batch):\n        out[i, : seq.size(0)] = seq\n    return out\n\n\ndef alpaca_collate(batch, pad_idx: int):\n    inputs, labels = zip(*batch)\n    inputs_padded = pad_sequence(inputs, pad_idx)\n    labels = torch.stack(labels)\n    return inputs_padded, labels\n\n\n# --------------------------------------------------------------------------------------\n# Public API\n# --------------------------------------------------------------------------------------\n\ndef build_char_vocab():\n    special_tokens = [\"\u003cpad\u003e\", \"\u003cunk\u003e\"]\n    ascii_chars = list(string.printable)\n    vocab_list = special_tokens + ascii_chars\n    vocab = {ch: idx for idx, ch in enumerate(vocab_list)}\n    return vocab\n\n\ndef get_num_classes(dataset_cfg: Dict) -\u003e int:\n    if dataset_cfg.name.lower() == \"cifar-10\":\n        return 10\n    elif dataset_cfg.name.lower() == \"alpaca-cleaned\":\n        return 2\n    else:\n        raise ValueError(f\"Unknown dataset {dataset_cfg.name}\")\n\n\ndef build_dataloaders(dataset_cfg: Dict, training_cfg: Dict):\n    batch_size = training_cfg.batch_size\n    num_workers = training_cfg.get(\"num_workers\", 2)\n\n    if dataset_cfg.name.lower() == \"cifar-10\":\n        # Transforms\n        train_tfms = []\n        if dataset_cfg.augmentations.get(\"random_crop\", False):\n            train_tfms.append(T.RandomCrop(dataset_cfg.image_size, padding=4))\n        if dataset_cfg.augmentations.get(\"random_flip\", \"\") == \"horizontal\":\n            train_tfms.append(T.RandomHorizontalFlip())\n        train_tfms += [\n            T.ToTensor(),\n            T.Normalize(mean=dataset_cfg.normalization.mean, std=dataset_cfg.normalization.std),\n        ]\n        test_tfms = [\n            T.ToTensor(),\n            T.Normalize(mean=dataset_cfg.normalization.mean, std=dataset_cfg.normalization.std),\n        ]\n\n        full_train = CIFAR10Dataset(dataset_cfg, train=True, transform=T.Compose(train_tfms))\n        val_size = dataset_cfg.splits.val\n        train_size = dataset_cfg.splits.train\n        train_set, val_set = random_split(\n            full_train,\n            [train_size, val_size],\n            generator=torch.Generator().manual_seed(42),\n        )\n        test_set = CIFAR10Dataset(dataset_cfg, train=False, transform=T.Compose(test_tfms))\n\n        train_loader = DataLoader(\n            train_set,\n            batch_size=batch_size,\n            shuffle=True,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        val_loader = DataLoader(\n            val_set,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        test_loader = DataLoader(\n            test_set,\n            batch_size=batch_size,\n            shuffle=False,\n            num_workers=num_workers,\n            pin_memory=True,\n        )\n        return train_loader, val_loader, test_loader\n\n    elif dataset_cfg.name.lower() == \"alpaca-cleaned\":\n        vocab = build_char_vocab()\n        # Using 80/10/10 split\n        full_dataset = AlpacaLengthDataset(\"train\", dataset_cfg, vocab)\n        n_total = len(full_dataset)\n        n_val = n_total // 10\n        n_test = n_total // 10\n        n_train = n_total - n_val - n_test\n        train_set, val_set, test_set = random_split(\n            full_dataset,\n            [n_train, n_val, n_test],\n            generator=torch.Generator().manual_seed(42),\n        )\n\n        collate = lambda batch: alpaca_collate(batch, vocab[\"\u003cpad\u003e\"])\n        train_loader = DataLoader(\n            train_set,\n            batch_size=batch_size,\n            shuffle=True,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        val_loader = DataLoader(\n            val_set,\n            batch_size=batch_size,\n            shuffle=False,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        test_loader = DataLoader(\n            test_set,\n            batch_size=batch_size,\n            shuffle=False,\n            collate_fn=collate,\n            num_workers=num_workers,\n        )\n        return train_loader, val_loader, test_loader\n\n    else:\n        raise ValueError(f\"Unsupported dataset: {dataset_cfg.name}\")\n", "pyproject_toml": "[project]\nname = \"hydra_experiment\"\nversion = \"0.1.0\"\ndescription = \"Hydra driven experiment framework\"\n\n[tool.poetry.dependencies]\npython = \"^3.9\"\ntorch = \"^2.0.0\"\ntorchvision = \"^0.15.0\"\ntransformers = \"^4.35.0\"\nhydra-core = \"^1.3.2\"\noptuna = \"^3.5.0\"\ndatasets = \"^2.14.6\"\nmatplotlib = \"^3.8.0\"\nwandb = \"^0.16.0\"\n\n[build-system]\nrequires = [\"setuptools\", \"wheel\"]\n\n", "train_py": "import json\nimport os\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Dict, Tuple\n\nimport hydra\nimport numpy as np\nimport torch\nimport torch.nn.functional as F\nimport wandb\nfrom omegaconf import DictConfig, OmegaConf\nfrom torch.cuda.amp import autocast, GradScaler\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR\nfrom torch.utils.data import DataLoader\n\nfrom .model import build_model\nfrom .preprocess import build_dataloaders, get_num_classes\n\n# --------------------------------------------------------------------------------------\n# Utility helpers\n# --------------------------------------------------------------------------------------\n\ndef set_seed(seed: int = 42):\n    \"\"\"Ensure deterministic behaviour where possible.\"\"\"\n    import random\n    import numpy as np\n\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n\n\ndef create_optimizer(model: torch.nn.Module, cfg: Dict[str, Any]):\n    params = [p for p in model.parameters() if p.requires_grad]\n    if cfg.optimizer == \"sgd\":\n        return torch.optim.SGD(\n            params,\n            lr=cfg.learning_rate,\n            momentum=cfg.get(\"momentum\", 0.9),\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    elif cfg.optimizer == \"adam\":\n        return torch.optim.Adam(\n            params,\n            lr=cfg.learning_rate,\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    elif cfg.optimizer == \"adamw\":\n        return torch.optim.AdamW(\n            params,\n            lr=cfg.learning_rate,\n            weight_decay=cfg.get(\"weight_decay\", 0.0),\n        )\n    else:\n        raise ValueError(f\"Unsupported optimizer: {cfg.optimizer}\")\n\n\ndef create_scheduler(optimizer: torch.optim.Optimizer, cfg: Dict[str, Any]):\n    if \"lr_scheduler\" not in cfg or cfg.lr_scheduler is None:\n        return None\n    sched_cfg = cfg.lr_scheduler\n    if sched_cfg.type == \"cosine\":\n        return CosineAnnealingLR(optimizer, T_max=sched_cfg.T_max)\n    elif sched_cfg.type == \"linear\":\n        return LinearLR(\n            optimizer,\n            start_factor=1.0,\n            end_factor=0.0,\n            total_iters=sched_cfg.get(\"warmup_steps\", 0) + cfg.epochs,\n        )\n    else:\n        raise ValueError(f\"Unsupported scheduler {sched_cfg.type}\")\n\n\ndef accuracy(pred: torch.Tensor, target: torch.Tensor) -\u003e float:\n    preds = pred.argmax(dim=1)\n    correct = (preds == target).float().sum().item()\n    return correct / target.numel()\n\n\ndef save_wandb_metadata(iteration: str, run_id: str):\n    meta_dir = Path(f\".research/iteration{iteration}\")\n    meta_dir.mkdir(parents=True, exist_ok=True)\n    meta_path = meta_dir / \"wandb_metadata.json\"\n    with meta_path.open(\"w\") as f:\n        json.dump(\n            {\n                \"wandb_entity\": \"gengaru617\",\n                \"wandb_project\": \"251014-test\",\n                \"wandb_run_id\": run_id,\n            },\n            f,\n            indent=2,\n        )\n\n\ndef train_one_epoch(\n    model: torch.nn.Module,\n    loader: DataLoader,\n    optimizer: torch.optim.Optimizer,\n    device: torch.device,\n    scaler: GradScaler,\n):\n    model.train()\n    losses = []\n    accuracies = []\n    for inputs, targets in loader:\n        inputs, targets = inputs.to(device), targets.to(device)\n        optimizer.zero_grad()\n        with autocast():\n            outputs = model(inputs)\n            loss = F.cross_entropy(outputs, targets)\n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n        losses.append(loss.item())\n        accuracies.append(accuracy(outputs.detach(), targets))\n    return float(np.mean(losses)), float(np.mean(accuracies))\n\n\ndef evaluate(\n    model: torch.nn.Module,\n    loader: DataLoader,\n    device: torch.device,\n):\n    model.eval()\n    losses = []\n    accuracies = []\n    with torch.no_grad():\n        for inputs, targets in loader:\n            inputs, targets = inputs.to(device), targets.to(device)\n            outputs = model(inputs)\n            loss = F.cross_entropy(outputs, targets)\n            losses.append(loss.item())\n            accuracies.append(accuracy(outputs, targets))\n    return float(np.mean(losses)), float(np.mean(accuracies))\n\n# --------------------------------------------------------------------------------------\n# Main training entrypoint managed by Hydra\n# --------------------------------------------------------------------------------------\n\n\n@hydra.main(config_path=\"../../config\", config_name=\"config\", version_base=\"1.3\")\ndef main(cfg: DictConfig):\n    # Ensure output directory exists\n    results_dir = Path(cfg.results_dir) / cfg.run_id\n    results_dir.mkdir(parents=True, exist_ok=True)\n\n    # ----------------------------------------------------------------------------------\n    # 1. Reproducibility\n    # ----------------------------------------------------------------------------------\n    set_seed(42)\n\n    # ----------------------------------------------------------------------------------\n    # 2. WandB initialisation (safe-offline if key missing)\n    # ----------------------------------------------------------------------------------\n    wandb_mode = \"online\" if os.getenv(\"WANDB_API_KEY\") else \"offline\"\n    wandb_run = wandb.init(\n        project=cfg.wandb.get(\"project\", \"251014-test\"),\n        entity=cfg.wandb.get(\"entity\", \"gengaru617\"),\n        name=cfg.wandb.get(\"run_name\", cfg.run_id),\n        tags=cfg.wandb.get(\"tags\", []),\n        config=OmegaConf.to_container(cfg, resolve=True, throw_on_missing=True),\n        mode=wandb_mode,\n    )\n\n    save_wandb_metadata(os.getenv(\"EXPERIMENT_ITERATION\", \"0\"), wandb_run.id)\n\n    # ----------------------------------------------------------------------------------\n    # 3. Data pipeline\n    # ----------------------------------------------------------------------------------\n    dataloaders = build_dataloaders(cfg.dataset, cfg.training)\n    train_loader, val_loader, test_loader = dataloaders\n    num_classes = get_num_classes(cfg.dataset)\n\n    # ----------------------------------------------------------------------------------\n    # 4. Model\n    # ----------------------------------------------------------------------------------\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model = build_model(cfg.model, num_classes=num_classes)\n    model.to(device)\n\n    # ----------------------------------------------------------------------------------\n    # 5. Optimizer \u0026 Scheduler\n    # ----------------------------------------------------------------------------------\n    optimizer = create_optimizer(model, cfg.training)\n    scheduler = create_scheduler(optimizer, cfg.training)\n    scaler = GradScaler()\n\n    # ----------------------------------------------------------------------------------\n    # 6. Training loop\n    # ----------------------------------------------------------------------------------\n    history = []\n    best_val_acc = 0.0\n    best_ckpt_path = results_dir / \"best_model.pt\"\n\n    for epoch in range(cfg.training.epochs):\n        train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, device, scaler)\n        val_loss, val_acc = evaluate(model, val_loader, device)\n        if scheduler is not None:\n            scheduler.step()\n\n        wandb.log(\n            {\n                \"epoch\": epoch + 1,\n                \"train_loss\": train_loss,\n                \"train_accuracy\": train_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            },\n            step=epoch + 1,\n        )\n\n        history.append(\n            {\n                \"epoch\": epoch + 1,\n                \"train_loss\": train_loss,\n                \"train_accuracy\": train_acc,\n                \"val_loss\": val_loss,\n                \"val_accuracy\": val_acc,\n            }\n        )\n\n        # Save best checkpoint\n        if val_acc \u003e best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), best_ckpt_path)\n\n    # ----------------------------------------------------------------------------------\n    # 7. Final evaluation on test-set\n    # ----------------------------------------------------------------------------------\n    test_loss, test_acc = evaluate(model, test_loader, device)\n    wandb.summary.update({\"test_loss\": test_loss, \"test_accuracy\": test_acc})\n\n    # ----------------------------------------------------------------------------------\n    # 8. Serialize results\n    # ----------------------------------------------------------------------------------\n    results = {\n        \"run_id\": cfg.run_id,\n        \"history\": history,\n        \"best_val_accuracy\": best_val_acc,\n        \"test_loss\": test_loss,\n        \"test_accuracy\": test_acc,\n        \"best_model_path\": str(best_ckpt_path),\n        \"wandb_url\": wandb_run.url,\n    }\n\n    with (results_dir / \"results.json\").open(\"w\") as f:\n        json.dump(results, f, indent=2)\n\n    # Print detailed description + metrics JSON as required by spec.\n    exp_description = (\n        f\"Experiment {cfg.run_id}:\\n\"\n        f\"Method: {cfg.method}\\n\"\n        f\"Model: {cfg.model.name} (variant={cfg.model.get(\u0027variant\u0027, \u0027N/A\u0027)})\\n\"\n        f\"Dataset: {cfg.dataset.name}\\n\"\n        f\"Epochs: {cfg.training.epochs}, Batch size: {cfg.training.batch_size}, LR: {cfg.training.learning_rate}\\n\"\n    )\n    print(\"#\" * 80)\n    print(exp_description)\n    print(\"#\" * 80)\n\n    print(json.dumps(results))\n\n    # Upload best model as artifact\n    artifact = wandb.Artifact(\"model-ckpt\", type=\"model\")\n    artifact.add_file(str(best_ckpt_path))\n    wandb_run.log_artifact(artifact)\n    wandb.finish()\n\n\nif __name__ == \"__main__\":\n    main()\n"}

Analyze the experiment code thoroughly. Ensure it is complete, executable, and ready for publication-quality research experiments.
Output:
{
    "is_code_ready": false,
    "code_issue": "Code violates several core validation criteria:\n\n1. Immediate executability breaks for the DistilBERT-text runs.\n    build_dataloaders() returns a single tensor (char-level ids) but DistilBertTextClassifier.forward() expects (input_ids, attention_mask).  train_one_epoch() therefore calls the module with wrong arguments and crashes.\n    No tokenizer / attention-mask preparation is implemented for the sentence-piece setting declared in the run config.\n\n2. Placeholder / simplified logic still present (requirement 1).\n    build_model() hard-codes vocab_size = 100 with a simplified here comment  not production quality.\n    DistilBertVision ignores the sequence_length parameter.\n\n3. Package structure is incomplete (requirement 5).\n    src/__init__.py is missing, so the relative imports (from .model, .preprocess) in train.py fail when executed with python -m src.train.\n\n4. Data pipeline is incomplete for NLP runs (requirement 3).\n    Only a toy length-based classification is implemented; no instruction-following preprocessing, tokenizer handling, or attention-mask building as described in the run configs.\n\nBecause of these issues the code will raise runtime errors and does not satisfy the publication-ready / fully-implemented criteria."
}
